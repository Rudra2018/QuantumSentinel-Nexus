#!/usr/bin/env python3
"""
🤖 QuantumSentinel AI/ML Vulnerability Detection Engine
Advanced machine learning models for vulnerability detection and analysis
"""

import asyncio
import logging
import os
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict

# ML imports with graceful fallback
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import classification_report
    import numpy as np
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
    from .huggingface_trainer import HuggingFaceTrainer, train_vulnerability_model
    TRANSFORMERS_AVAILABLE = True
    HUGGINGFACE_TRAINER_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    HUGGINGFACE_TRAINER_AVAILABLE = False

# Import comprehensive vulnerability mapper
try:
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent.parent))
    from security_frameworks.cwe_sans_owasp_mappings import ComprehensiveVulnMapper, create_vulnerability_mapper
    from security_engines.kernel.kernel_vuln_engine import KernelVulnEngine, VulnerabilityCategory as KernelVulnCategory
    COMPREHENSIVE_MAPPER_AVAILABLE = True
    KERNEL_ENGINE_AVAILABLE = True
except ImportError:
    COMPREHENSIVE_MAPPER_AVAILABLE = False
    KERNEL_ENGINE_AVAILABLE = False

logger = logging.getLogger("QuantumSentinel.AIVulnDetector")

@dataclass
class AIFinding:
    """AI-detected security finding"""
    id: str
    title: str
    severity: str
    confidence: str
    description: str
    impact: str
    recommendation: str
    vulnerability_type: str
    confidence_score: float
    model_used: str
    evidence: Optional[str] = None
    cwe_id: Optional[str] = None

class MLVulnerabilityDetector:
    """Advanced ML-based vulnerability detection engine"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.findings = []
        self.models = {}
        self.vectorizer = None

        # Initialize comprehensive vulnerability mapper
        if COMPREHENSIVE_MAPPER_AVAILABLE:
            self.vuln_mapper = create_vulnerability_mapper()
        else:
            self.vuln_mapper = None

        # Initialize kernel vulnerability engine
        if KERNEL_ENGINE_AVAILABLE:
            self.kernel_engine = None  # Will be initialized async
        else:
            self.kernel_engine = None

        # Comprehensive training data covering CWE Top 25, SANS Top 25, and OWASP categories
        self.training_data = [
            # CWE-787: Out-of-bounds Write
            ("strcpy(dest, src)", "cwe_787_out_of_bounds_write"),
            ("strcat(buffer, input)", "cwe_787_out_of_bounds_write"),
            ("sprintf(buffer, format, args)", "cwe_787_out_of_bounds_write"),
            ("gets(buffer)", "cwe_787_out_of_bounds_write"),
            ("memcpy(dest, src, len)", "cwe_787_out_of_bounds_write"),

            # CWE-79: Cross-site Scripting
            ("<script>alert('xss')</script>", "cwe_79_xss"),
            ("document.innerHTML = userInput", "cwe_79_xss"),
            ("element.outerHTML = data", "cwe_79_xss"),
            ("eval(userCode)", "cwe_79_xss"),
            ("document.write(userContent)", "cwe_79_xss"),

            # CWE-89: SQL Injection
            ("SELECT * FROM users WHERE id = '{}'", "cwe_89_sql_injection"),
            ("var query = 'SELECT * FROM users WHERE id = ' + userId", "cwe_89_sql_injection"),
            ("DELETE FROM table WHERE column = '" + input + "'", "cwe_89_sql_injection"),
            ("UPDATE users SET name = '" + name + "' WHERE id = " + id", "cwe_89_sql_injection"),
            ("INSERT INTO users VALUES ('" + user + "')", "cwe_89_sql_injection"),

            # CWE-416: Use After Free
            ("free(ptr); ptr->data = value", "cwe_416_use_after_free"),
            ("delete object; object.method()", "cwe_416_use_after_free"),
            ("kfree(kernel_ptr); kernel_ptr->field", "cwe_416_use_after_free"),
            ("vfree(vm_ptr); vm_ptr[index]", "cwe_416_use_after_free"),

            # CWE-78: OS Command Injection
            ("system('rm -rf /' + userInput)", "cwe_78_command_injection"),
            ("exec(user_command)", "cwe_78_command_injection"),
            ("os.system(command)", "cwe_78_command_injection"),
            ("subprocess.call(userCmd, shell=True)", "cwe_78_command_injection"),
            ("Runtime.getRuntime().exec(cmd)", "cwe_78_command_injection"),

            # CWE-20: Improper Input Validation
            ("int size = atoi(userInput)", "cwe_20_input_validation"),
            ("char buffer[userSize]", "cwe_20_input_validation"),
            ("malloc(userSize)", "cwe_20_input_validation"),
            ("array[userIndex] = value", "cwe_20_input_validation"),

            # CWE-125: Out-of-bounds Read
            ("return buffer[index + offset]", "cwe_125_out_of_bounds_read"),
            ("memcpy(dest, src + overflow, size)", "cwe_125_out_of_bounds_read"),
            ("value = array[size + 1]", "cwe_125_out_of_bounds_read"),

            # CWE-22: Path Traversal
            ("fopen('../../../etc/passwd', 'r')", "cwe_22_path_traversal"),
            ("include($_GET['file'])", "cwe_22_path_traversal"),
            ("readFile('../../../../sensitive.txt')", "cwe_22_path_traversal"),
            ("open(basePath + '../' + fileName)", "cwe_22_path_traversal"),

            # CWE-352: Cross-Site Request Forgery
            ("<form method='post' action='/transfer'>", "cwe_352_csrf"),
            ("$.post('/api/delete', data)", "cwe_352_csrf"),
            ("fetch('/api/update', {method: 'POST'})", "cwe_352_csrf"),
            ("XMLHttpRequest.open('POST', '/action')", "cwe_352_csrf"),

            # CWE-434: Unrestricted File Upload
            ("move_uploaded_file($_FILES['upload'])", "cwe_434_file_upload"),
            ("copy(tmpFile, destination)", "cwe_434_file_upload"),
            ("file_put_contents(fileName, data)", "cwe_434_file_upload"),
            ("upload.save(uploadPath)", "cwe_434_file_upload"),

            # CWE-476: NULL Pointer Dereference
            ("if (ptr == NULL) return *ptr", "cwe_476_null_deref"),
            ("malloc(size); ptr->field = value", "cwe_476_null_deref"),
            ("calloc(1, size); *ptr = data", "cwe_476_null_deref"),

            # CWE-502: Deserialization of Untrusted Data
            ("pickle.loads(userInput)", "cwe_502_deserialization"),
            ("yaml.load(untrustedData)", "cwe_502_deserialization"),
            ("ObjectInputStream.readObject()", "cwe_502_deserialization"),
            ("JSON.parse(userData)", "cwe_502_deserialization"),
            ("unserialize($userData)", "cwe_502_deserialization"),

            # CWE-190: Integer Overflow
            ("int result = a * b", "cwe_190_integer_overflow"),
            ("size_t total = count * itemSize", "cwe_190_integer_overflow"),
            ("malloc(num * sizeof(struct))", "cwe_190_integer_overflow"),
            ("buffer[index + offset] = value", "cwe_190_integer_overflow"),

            # CWE-287: Improper Authentication
            ("if (password == 'admin123')", "cwe_287_improper_auth"),
            ("if (user.name == 'root')", "cwe_287_improper_auth"),
            ("login(username, '')", "cwe_287_improper_auth"),
            ("authenticate() { return true; }", "cwe_287_improper_auth"),

            # CWE-732: Incorrect Permission Assignment
            ("chmod(file, 0777)", "cwe_732_permissions"),
            ("umask(0)", "cwe_732_permissions"),
            ("setPermissions(WORLD_WRITABLE)", "cwe_732_permissions"),
            ("File.createTempFile().setWritable(true, false)", "cwe_732_permissions"),

            # CWE-798: Hard-coded Credentials
            ("password = 'admin123'", "cwe_798_hardcoded_creds"),
            ("api_key = 'sk-1234567890'", "cwe_798_hardcoded_creds"),
            ("SECRET_KEY = 'secret123'", "cwe_798_hardcoded_creds"),
            ("DB_PASSWORD = 'password'", "cwe_798_hardcoded_creds"),

            # CWE-862: Missing Authorization
            ("function deleteUser() { db.delete(userId); }", "cwe_862_missing_authz"),
            ("app.post('/admin', handler)", "cwe_862_missing_authz"),
            ("@RequestMapping('/sensitive')", "cwe_862_missing_authz"),

            # CWE-77: Command Injection
            ("eval('ls ' + userDir)", "cwe_77_command_injection"),
            ("shell_exec($userCommand)", "cwe_77_command_injection"),
            ("popen(command, 'r')", "cwe_77_command_injection"),

            # CWE-918: Server-Side Request Forgery
            ("requests.get(userUrl)", "cwe_918_ssrf"),
            ("fetch(userProvidedUrl)", "cwe_918_ssrf"),
            ("file_get_contents($url)", "cwe_918_ssrf"),
            ("curl_init($userUrl)", "cwe_918_ssrf"),

            # CWE-306: Missing Authentication
            ("/admin/ without authentication", "cwe_306_missing_auth"),
            ("function sensitiveOperation() { /* no auth check */ }", "cwe_306_missing_auth"),
            ("@GetMapping('/private') public void method()", "cwe_306_missing_auth"),

            # CWE-269: Improper Privilege Management
            ("setuid(0)", "cwe_269_privilege_mgmt"),
            ("sudo command", "cwe_269_privilege_mgmt"),
            ("runas administrator", "cwe_269_privilege_mgmt"),
            ("escalate_privileges()", "cwe_269_privilege_mgmt"),

            # CWE-611: XML External Entity
            ("DocumentBuilder.parse(userXml)", "cwe_611_xxe"),
            ("XMLReader.parse(inputXml)", "cwe_611_xxe"),
            ("simplexml_load_string($xml)", "cwe_611_xxe"),

            # CWE-94: Code Injection
            ("eval(userCode)", "cwe_94_code_injection"),
            ("exec(userScript)", "cwe_94_code_injection"),
            ("Function(userFunction)()", "cwe_94_code_injection"),
            ("compile(userCode, 'string', 'exec')", "cwe_94_code_injection"),

            # OWASP Mobile Top 10
            ("WebView.loadUrl(userUrl)", "mobile_m1_platform_usage"),
            ("SharedPreferences.edit().putString('password', pass)", "mobile_m2_insecure_storage"),
            ("http://api.example.com/data", "mobile_m3_insecure_communication"),
            ("login(username, '')", "mobile_m4_insecure_auth"),
            ("MD5(password)", "mobile_m5_weak_crypto"),
            ("if (user.role != 'admin')", "mobile_m6_insecure_authz"),
            ("gets(buffer)", "mobile_m7_code_quality"),
            ("Runtime.getRuntime().exec()", "mobile_m8_code_tampering"),
            ("/* No obfuscation */", "mobile_m9_reverse_engineering"),
            ("if (DEBUG) { showAdminPanel(); }", "mobile_m10_extraneous_functionality"),

            # OWASP API Top 10
            ("/api/users/{id} without authorization", "api_api1_broken_object_authz"),
            ("Bearer token without validation", "api_api2_broken_auth"),
            ("return user.toJSON()", "api_api3_excessive_data_exposure"),
            ("no rate limiting", "api_api4_lack_resources_limiting"),
            ("admin function without role check", "api_api5_broken_function_authz"),
            ("purchase without limits", "api_api6_mass_assignment"),
            ("fetch(userProvidedUrl)", "api_api7_ssrf"),
            ("debug = true in production", "api_api8_security_misconfiguration"),
            ("/v1/deprecated-endpoint", "api_api9_improper_inventory"),
            ("trust third-party API data", "api_api10_unsafe_consumption"),

            # OWASP Serverless Top 10
            ("lambda function with SQL injection", "serverless_sas1_injection"),
            ("function without proper IAM", "serverless_sas2_broken_auth"),
            ("overprivileged execution role", "serverless_sas3_insecure_deployment"),
            ("Action: '*', Resource: '*'", "serverless_sas4_overprivileged"),
            ("console.log(sensitiveData)", "serverless_sas5_inadequate_monitoring"),
            ("hardcoded secrets in environment", "serverless_sas6_insecure_secrets"),
            ("cross-account invoke permissions", "serverless_sas7_cross_service_vulnerabilities"),
            ("outdated npm packages", "serverless_sas8_dependency_vulnerabilities"),
            ("detailed error messages", "serverless_sas9_improper_exception_handling"),
            ("no timeout or memory limits", "serverless_sas10_functions_dos"),

            # Kernel-specific vulnerabilities
            ("copy_from_user(buffer, userPtr, size)", "kernel_user_copy"),
            ("copy_to_user(userPtr, buffer, size)", "kernel_user_copy"),
            ("kmalloc(userSize, GFP_KERNEL)", "kernel_memory_allocation"),
            ("kfree(ptr); ptr->field = value", "kernel_use_after_free"),
            ("ioctl handler without validation", "kernel_ioctl_vulnerability"),
            ("syscall hook installation", "kernel_syscall_hooking"),
            ("hide_process() function", "kernel_rootkit_behavior"),

            # Binary analysis patterns
            ("ROP gadget found", "binary_rop_gadget"),
            ("NOP sled detected", "binary_nop_sled"),
            ("shellcode pattern", "binary_shellcode"),
            ("anti-debug techniques", "binary_anti_debug"),
            ("packed executable", "binary_packing"),
            ("suspicious entropy", "binary_suspicious_entropy"),

            # Safe patterns (important for ML training)
            ("prepared statement with parameters", "safe_code"),
            ("input validation and sanitization", "safe_code"),
            ("proper bounds checking", "safe_code"),
            ("secure random number generation", "safe_code"),
            ("proper error handling", "safe_code"),
            ("cryptographically secure hash", "safe_code"),
            ("parameterized query", "safe_code"),
            ("CSRF token validation", "safe_code"),
            ("file type validation", "safe_code"),
            ("authentication required", "safe_code"),
            ("authorization check", "safe_code"),
            ("input length validation", "safe_code"),
            ("output encoding", "safe_code"),
            ("secure communication (HTTPS)", "safe_code"),
            ("proper session management", "safe_code"),
        ]

        # Enhanced binary analysis training data
        self.binary_training_data = [
            # Buffer overflow patterns
            ("strcpy(dest, src)", "buffer_overflow"),
            ("strcat(dest, src)", "buffer_overflow"),
            ("sprintf(buffer, format, args)", "buffer_overflow"),
            ("gets(buffer)", "buffer_overflow"),
            ("scanf(\"%s\", buffer)", "buffer_overflow"),
            ("memcpy(dest, src, size)", "potential_buffer_overflow"),
            ("memmove(dest, src, size)", "potential_buffer_overflow"),

            # Format string vulnerabilities
            ("printf(user_input)", "format_string"),
            ("fprintf(file, user_input)", "format_string"),
            ("sprintf(buffer, user_input)", "format_string"),
            ("syslog(LOG_INFO, user_input)", "format_string"),

            # Memory corruption patterns
            ("malloc(size)", "memory_allocation"),
            ("free(ptr)", "memory_deallocation"),
            ("realloc(ptr, size)", "memory_reallocation"),
            ("calloc(num, size)", "memory_allocation"),
            ("double free", "double_free"),
            ("use after free", "use_after_free"),

            # Integer overflow patterns
            ("size_t len = strlen(input) + 1", "potential_integer_overflow"),
            ("int result = a * b", "potential_integer_overflow"),
            ("unsigned int size = user_size", "integer_handling"),

            # Privilege escalation patterns
            ("setuid(0)", "privilege_escalation"),
            ("seteuid(0)", "privilege_escalation"),
            ("setgid(0)", "privilege_escalation"),
            ("sudo", "privilege_escalation"),

            # Cryptographic vulnerabilities
            ("MD5", "weak_crypto"),
            ("SHA1", "weak_crypto"),
            ("DES", "weak_crypto"),
            ("RC4", "weak_crypto"),
            ("rand()", "weak_random"),
            ("srand(time(NULL))", "weak_random"),

            # Network security patterns
            ("socket(AF_INET, SOCK_STREAM, 0)", "network_operation"),
            ("bind(sockfd, addr, addrlen)", "network_bind"),
            ("accept(sockfd, addr, addrlen)", "network_accept"),
            ("SSL_CTX_new", "ssl_operation"),
            ("HTTP", "unencrypted_protocol"),
            ("FTP", "unencrypted_protocol"),

            # Binary exploitation patterns
            ("ROP gadget", "rop_gadget"),
            ("JOP gadget", "jop_gadget"),
            ("ret2libc", "ret2libc"),
            ("shellcode", "shellcode"),
            ("NOP sled", "nop_sled"),

            # Anti-analysis patterns
            ("packed", "packing"),
            ("obfuscated", "obfuscation"),
            ("anti-debug", "anti_debug"),
            ("anti-vm", "anti_vm"),
            ("UPX", "upx_packing"),

            # Kernel-specific patterns
            ("KERNEL_DS", "kernel_code"),
            ("copy_from_user", "kernel_user_copy"),
            ("copy_to_user", "kernel_user_copy"),
            ("kmalloc", "kernel_memory"),
            ("kfree", "kernel_memory"),
            ("ioctl", "kernel_ioctl"),

            # Mobile-specific patterns
            ("CFBundleExecutable", "ios_binary"),
            ("AndroidManifest.xml", "android_binary"),
            ("classes.dex", "android_dex"),
            ("libssl.so", "native_library"),
            ("JNI", "jni_interface"),

            # Safe patterns
            ("strncpy(dest, src, size)", "safe_string_op"),
            ("strncat(dest, src, size)", "safe_string_op"),
            ("snprintf(buffer, size, format)", "safe_format"),
            ("fgets(buffer, size, file)", "safe_input"),
            ("secure_random", "secure_random"),
            ("AES-256", "strong_crypto"),
            ("RSA-2048", "strong_crypto"),
            ("HTTPS", "secure_protocol"),
        ]

        # Assembly/disassembly patterns for binary analysis
        self.asm_patterns = {
            # x86/x64 vulnerability patterns
            "buffer_overflow": [
                r"mov.*esp.*ebp",  # Stack manipulation
                r"rep\s+stos",      # String operations without bounds
                r"call.*strcpy",    # Dangerous function calls
                r"call.*strcat",
                r"call.*sprintf",
                r"call.*gets",
            ],
            "format_string": [
                r"call.*printf",    # Printf family without format validation
                r"call.*fprintf",
                r"call.*sprintf",
                r"push.*%[^,]*%",   # Format string indicators
            ],
            "integer_overflow": [
                r"imul.*eax",       # Integer multiplication
                r"add.*eax.*ebx",   # Addition operations
                r"shl.*eax",        # Bit shifting
                r"sal.*eax",
            ],
            "rop_gadgets": [
                r"pop.*ret",        # ROP gadget patterns
                r"pop.*pop.*ret",
                r"add.*esp.*ret",
                r"xchg.*ret",
            ],
            "shellcode": [
                r"\x90+",           # NOP sleds
                r"\x31\xc0",        # xor eax, eax
                r"\xcc",            # int3 (breakpoint)
                r"\xeb\x",          # jmp short
            ]
        }

    async def initialize_models(self):
        """Initialize AI/ML models"""

        logger.info("Initializing AI/ML models...")

        # Initialize traditional ML model
        if SKLEARN_AVAILABLE:
            await self._train_traditional_model()
            await self._train_binary_classifier()
            logger.info("✅ Traditional ML model initialized")

        # Initialize transformer model
        if TRANSFORMERS_AVAILABLE:
            await self._initialize_transformer_model()
            logger.info("✅ Transformer model initialized")

        # Initialize fine-tuned model if available
        if HUGGINGFACE_TRAINER_AVAILABLE:
            await self._initialize_fine_tuned_model()

        if not SKLEARN_AVAILABLE and not TRANSFORMERS_AVAILABLE:
            logger.warning("⚠️ No ML libraries available, using rule-based detection only")

    async def _train_traditional_model(self):
        """Train traditional ML model for vulnerability detection"""

        try:
            # Prepare training data
            texts = [item[0] for item in self.training_data]
            labels = [item[1] for item in self.training_data]

            # Vectorize text
            self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
            X = self.vectorizer.fit_transform(texts)

            # Train classifier
            self.models['traditional'] = RandomForestClassifier(n_estimators=100, random_state=42)
            self.models['traditional'].fit(X, labels)

            logger.info("Traditional ML model trained successfully")

        except Exception as e:
            logger.error(f"Failed to train traditional model: {e}")

    async def _train_binary_classifier(self):
        """Train binary vulnerability classifier using binary-specific training data"""
        try:
            # Prepare binary training data
            texts = [item[0] for item in self.binary_training_data]
            labels = [item[1] for item in self.binary_training_data]

            # Vectorize text using TF-IDF
            binary_vectorizer = TfidfVectorizer(
                max_features=2000,
                ngram_range=(1, 3),  # Use 1-3 gram features
                analyzer='word',
                lowercase=True
            )
            X = binary_vectorizer.fit_transform(texts)

            # Train Random Forest classifier specifically for binary analysis
            binary_classifier = RandomForestClassifier(
                n_estimators=200,
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                class_weight='balanced'  # Handle imbalanced classes
            )

            # Split data for training and validation
            X_train, X_test, y_train, y_test = train_test_split(
                X, labels, test_size=0.2, random_state=42, stratify=labels
            )

            # Train the model
            binary_classifier.fit(X_train, y_train)

            # Evaluate the model
            train_score = binary_classifier.score(X_train, y_train)
            test_score = binary_classifier.score(X_test, y_test)

            # Store the model and vectorizer
            self.models['binary_classifier'] = binary_classifier
            self.models['binary_vectorizer'] = binary_vectorizer

            logger.info(f"Binary classifier trained successfully - Train: {train_score:.3f}, Test: {test_score:.3f}")

            # Generate classification report
            y_pred = binary_classifier.predict(X_test)
            report = classification_report(y_test, y_pred, output_dict=True)
            logger.info(f"Binary classifier performance: {report['macro avg']}")

        except Exception as e:
            logger.error(f"Failed to train binary classifier: {e}")

    async def _initialize_transformer_model(self):
        """Initialize transformer-based model"""

        try:
            # Use a pre-trained model for text classification
            # In production, you would use a model fine-tuned for security
            self.models['transformer'] = pipeline(
                "text-classification",
                model="distilbert-base-uncased-finetuned-sst-2-english",
                return_all_scores=True
            )

            logger.info("Transformer model initialized successfully")

        except Exception as e:
            logger.error(f"Failed to initialize transformer model: {e}")

    async def _initialize_fine_tuned_model(self):
        """Initialize fine-tuned HuggingFace model if available"""
        try:
            trainer = HuggingFaceTrainer()
            fine_tuned_model = await trainer.load_fine_tuned_model()

            if fine_tuned_model:
                self.models['fine_tuned'] = fine_tuned_model
                logger.info("✅ Fine-tuned HuggingFace model loaded")
            else:
                logger.info("No fine-tuned model available, will use pre-trained models")
        except Exception as e:
            logger.error(f"Failed to initialize fine-tuned model: {e}")

    async def train_custom_model(self, num_samples: int = 2000, epochs: int = 3) -> Dict[str, Any]:
        """Train custom HuggingFace model with synthetic vulnerability data"""
        if not HUGGINGFACE_TRAINER_AVAILABLE:
            return {'error': 'HuggingFace trainer not available'}

        try:
            logger.info(f"Starting custom model training with {num_samples} samples, {epochs} epochs")

            # Run the training workflow
            training_result = await train_vulnerability_model(
                num_samples=num_samples,
                model_name="microsoft/codebert-base",
                epochs=epochs
            )

            if training_result['success']:
                # Reload the fine-tuned model
                await self._initialize_fine_tuned_model()
                logger.info("✅ Custom model training completed successfully")

            return training_result

        except Exception as e:
            logger.error(f"Failed to train custom model: {e}")
            return {'error': str(e), 'success': False}

    async def get_training_report(self) -> Dict[str, Any]:
        """Get comprehensive training report for the fine-tuned model"""
        if not HUGGINGFACE_TRAINER_AVAILABLE:
            return {'error': 'HuggingFace trainer not available'}

        try:
            trainer = HuggingFaceTrainer()
            report = await trainer.generate_training_report()
            return report
        except Exception as e:
            logger.error(f"Failed to get training report: {e}")
            return {'error': str(e)}

    async def analyze_code_snippet(self, code: str, file_path: str = None) -> Dict[str, Any]:
        """Analyze code snippet for vulnerabilities using AI/ML"""

        await self.initialize_models()

        results = {
            'timestamp': datetime.now().isoformat(),
            'code_snippet': code[:500],  # Limit for privacy
            'file_path': file_path,
            'findings': [],
            'vulnerability_score': 0.0,
            'models_used': []
        }

        try:
            # Traditional ML analysis
            if 'traditional' in self.models:
                traditional_results = await self._analyze_with_traditional_ml(code)
                results['findings'].extend(traditional_results)
                results['models_used'].append('traditional_ml')

            # Transformer analysis
            if 'transformer' in self.models:
                transformer_results = await self._analyze_with_transformer(code)
                results['findings'].extend(transformer_results)
                results['models_used'].append('transformer')

            # Fine-tuned model analysis (highest priority)
            if 'fine_tuned' in self.models:
                fine_tuned_results = await self._analyze_with_fine_tuned_model(code)
                results['findings'].extend(fine_tuned_results)
                results['models_used'].append('fine_tuned_huggingface')

            # Rule-based analysis (always available)
            rule_results = await self._analyze_with_rules(code, file_path)
            results['findings'].extend(rule_results)
            results['models_used'].append('rule_based')

            # Enhance findings with comprehensive CWE/SANS/OWASP mappings
            if self.vuln_mapper and results['findings']:
                enhanced_findings = await self._enhance_findings_with_comprehensive_mappings(results['findings'], code)
                results['findings'] = enhanced_findings
                results['models_used'].append('comprehensive_vuln_mapper')

            # Add kernel-specific analysis if applicable
            if self.kernel_engine and file_path and any(ext in file_path.lower() for ext in ['.ko', '.sys', '.kext']):
                kernel_findings = await self._analyze_with_kernel_engine(code, file_path)
                results['findings'].extend(kernel_findings)
                results['models_used'].append('kernel_vulnerability_engine')

            # Calculate overall vulnerability score
            if results['findings']:
                if isinstance(results['findings'][0], dict):
                    scores = [f.get('confidence_score', 0) for f in results['findings']]
                else:
                    scores = [f.confidence_score for f in results['findings']]
                results['vulnerability_score'] = max(scores) if scores else 0.0

            # Convert findings to dict if they aren't already
            if results['findings'] and not isinstance(results['findings'][0], dict):
                results['findings'] = [asdict(finding) for finding in results['findings']]

        except Exception as e:
            logger.error(f"AI analysis failed: {e}")
            results['error'] = str(e)

        return results

    async def _analyze_with_traditional_ml(self, code: str) -> List[AIFinding]:
        """Analyze code using traditional ML model"""

        findings = []

        try:
            if self.vectorizer and 'traditional' in self.models:
                # Vectorize code
                code_vector = self.vectorizer.transform([code])

                # Predict vulnerability
                prediction = self.models['traditional'].predict(code_vector)[0]
                probabilities = self.models['traditional'].predict_proba(code_vector)[0]
                confidence = max(probabilities)

                if prediction != 'safe_code' and confidence > 0.6:
                    finding = AIFinding(
                        id=f"AI-TRAD-{len(findings)+1:03d}",
                        title=f"ML Detected: {prediction.replace('_', ' ').title()}",
                        severity="MEDIUM" if confidence > 0.8 else "LOW",
                        confidence="High" if confidence > 0.8 else "Medium",
                        description=f"Traditional ML model detected potential {prediction.replace('_', ' ')}",
                        impact="Potential security vulnerability detected by ML analysis",
                        recommendation="Review code for security issues and apply appropriate fixes",
                        vulnerability_type=prediction,
                        confidence_score=float(confidence),
                        model_used="RandomForest",
                        evidence=code[:100]
                    )
                    findings.append(finding)

        except Exception as e:
            logger.error(f"Traditional ML analysis failed: {e}")

        return findings

    async def _analyze_with_transformer(self, code: str) -> List[AIFinding]:
        """Analyze code using transformer model"""

        findings = []

        try:
            if 'transformer' in self.models:
                # Note: This is a simplified example. In production, you would use
                # a model specifically trained for security vulnerability detection
                results = self.models['transformer'](code[:512])  # Limit input length

                for result in results:
                    if result['label'] == 'NEGATIVE' and result['score'] > 0.7:
                        finding = AIFinding(
                            id=f"AI-TRANS-{len(findings)+1:03d}",
                            title="Transformer Detected Potential Issue",
                            severity="LOW",
                            confidence="Medium",
                            description="Transformer model flagged potential security concern",
                            impact="Code pattern may indicate security risk",
                            recommendation="Manual review recommended",
                            vulnerability_type="pattern_analysis",
                            confidence_score=result['score'],
                            model_used="DistilBERT",
                            evidence=code[:100]
                        )
                        findings.append(finding)

        except Exception as e:
            logger.error(f"Transformer analysis failed: {e}")

        return findings

    async def _analyze_with_fine_tuned_model(self, code: str) -> List[AIFinding]:
        """Analyze code using fine-tuned HuggingFace model"""
        findings = []

        try:
            if 'fine_tuned' in self.models:
                classifier = self.models['fine_tuned']

                # Analyze code with the fine-tuned model
                trainer = HuggingFaceTrainer()
                analysis_result = await trainer.analyze_code(code, classifier)

                if analysis_result.get('vulnerability_detected', False):
                    confidence = analysis_result.get('confidence', 0.0)

                    # Map confidence to severity
                    if confidence > 0.8:
                        severity = "HIGH"
                        confidence_str = "High"
                    elif confidence > 0.6:
                        severity = "MEDIUM"
                        confidence_str = "Medium"
                    else:
                        severity = "LOW"
                        confidence_str = "Low"

                    finding = AIFinding(
                        id=f"AI-FINE-{len(findings)+1:03d}",
                        title="Fine-tuned Model Vulnerability Detection",
                        severity=severity,
                        confidence=confidence_str,
                        description=f"Fine-tuned HuggingFace model detected potential vulnerability with {confidence:.2%} confidence",
                        impact="Code may contain security vulnerability based on trained patterns",
                        recommendation="Review code for security issues and apply appropriate fixes",
                        vulnerability_type="ml_detected",
                        confidence_score=confidence,
                        model_used="Fine-tuned CodeBERT",
                        evidence=code[:150],
                        cwe_id="CWE-Unknown"  # Fine-tuned model could be enhanced to predict CWE
                    )
                    findings.append(finding)

        except Exception as e:
            logger.error(f"Fine-tuned model analysis failed: {e}")

        return findings

    async def _analyze_with_rules(self, code: str, file_path: str = None) -> List[AIFinding]:
        """Analyze code using rule-based detection"""

        findings = []

        # Security patterns
        patterns = {
            'sql_injection': [
                r'SELECT.*FROM.*WHERE.*=.*\+',
                r'query.*=.*\+.*user',
                r'WHERE.*=.*\$'
            ],
            'xss': [
                r'innerHTML.*=.*user',
                r'document\.write.*\(',
                r'eval\(.*user'
            ],
            'command_injection': [
                r'system\(.*user',
                r'exec\(.*user',
                r'shell_exec\('
            ],
            'hardcoded_secrets': [
                r'api[_-]?key["\s]*[:=]["\s]*[a-zA-Z0-9]{20,}',
                r'password["\s]*[:=]["\s]*["\w]{8,}',
                r'secret["\s]*[:=]["\s]*[a-zA-Z0-9]{16,}'
            ]
        }

        for vuln_type, pattern_list in patterns.items():
            for pattern in pattern_list:
                matches = re.finditer(pattern, code, re.IGNORECASE)
                for match in matches:
                    finding = AIFinding(
                        id=f"AI-RULE-{len(findings)+1:03d}",
                        title=f"Rule-Based Detection: {vuln_type.replace('_', ' ').title()}",
                        severity="HIGH" if vuln_type in ['sql_injection', 'command_injection'] else "MEDIUM",
                        confidence="High",
                        description=f"Rule-based pattern matching detected {vuln_type.replace('_', ' ')}",
                        impact="Pattern suggests potential security vulnerability",
                        recommendation="Review and remediate security issue",
                        vulnerability_type=vuln_type,
                        confidence_score=0.9,
                        model_used="rule_based",
                        evidence=match.group()[:100],
                        cwe_id=self._get_cwe_for_type(vuln_type)
                    )
                    findings.append(finding)

        return findings

    async def _enhance_findings_with_mappings(self, findings: List[AIFinding], code: str) -> List[Dict[str, Any]]:
        """Enhance findings with comprehensive OWASP/CWE mappings"""
        enhanced_findings = []

        for finding in findings:
            # Convert finding to dict if it's not already
            if hasattr(finding, '__dict__'):
                finding_dict = asdict(finding)
            else:
                finding_dict = finding

            # Get vulnerability type
            vuln_type = finding_dict.get('vulnerability_type', 'unknown')

            # Create mapping using OWASP/CWE mapper
            if vuln_type != 'unknown':
                try:
                    mapping = self.owasp_cwe_mapper.map_vulnerability(
                        vulnerability_type=vuln_type,
                        code_snippet=code[:200],  # First 200 chars for context
                        confidence=finding_dict.get('confidence_score', 0.5)
                    )

                    # Enhance the finding with mapping data
                    enhanced_finding = finding_dict.copy()
                    enhanced_finding.update({
                        'owasp_category': mapping.owasp_category,
                        'owasp_category_name': self._get_owasp_category_name(mapping.owasp_category),
                        'cwe_id': mapping.cwe_id,
                        'cwe_name': self._get_cwe_name(mapping.cwe_id),
                        'cvss_score': mapping.cvss_score,
                        'business_risk': mapping.business_risk,
                        'remediation_effort': mapping.remediation_effort,
                        'compliance_frameworks': mapping.compliance_frameworks,
                        'severity_enhanced': mapping.severity.value,
                        'mapped_by': 'owasp_cwe_mapper'
                    })

                    enhanced_findings.append(enhanced_finding)

                except Exception as e:
                    logger.warning(f"Failed to map vulnerability {vuln_type}: {e}")
                    enhanced_findings.append(finding_dict)
            else:
                enhanced_findings.append(finding_dict)

        return enhanced_findings

    def _get_owasp_category_name(self, category_id: str) -> str:
        """Get OWASP category name"""
        if self.owasp_cwe_mapper:
            category = self.owasp_cwe_mapper.get_owasp_category_details(category_id)
            if category:
                return category.name
        return "Unknown Category"

    def _get_cwe_name(self, cwe_id: str) -> str:
        """Get CWE name"""
        if self.owasp_cwe_mapper:
            cwe = self.owasp_cwe_mapper.get_cwe_details(cwe_id)
            if cwe:
                return cwe.name
        return "Unknown CWE"

    async def generate_compliance_report(self, scan_results: Dict[str, Any]) -> Dict[str, Any]:
        """Generate comprehensive compliance report"""
        if not self.owasp_cwe_mapper:
            return {'error': 'OWASP/CWE mapper not available'}

        # Extract findings from scan results
        findings = scan_results.get('findings', [])

        # Convert findings to VulnerabilityMapping objects
        vulnerability_mappings = []
        for finding in findings:
            if isinstance(finding, dict):
                vuln_type = finding.get('vulnerability_type', 'unknown')
                confidence = finding.get('confidence_score', 0.5)

                if vuln_type != 'unknown':
                    mapping = self.owasp_cwe_mapper.map_vulnerability(
                        vulnerability_type=vuln_type,
                        code_snippet=finding.get('evidence', ''),
                        confidence=confidence
                    )
                    vulnerability_mappings.append(mapping)

        # Generate compliance report
        compliance_report = self.owasp_cwe_mapper.generate_compliance_report(vulnerability_mappings)

        # Add scan metadata
        compliance_report['scan_metadata'] = {
            'scan_timestamp': scan_results.get('timestamp'),
            'target': scan_results.get('target', 'unknown'),
            'models_used': scan_results.get('models_used', []),
            'total_findings': len(findings),
            'enhanced_findings': len(vulnerability_mappings)
        }

        return compliance_report

    def _get_cwe_for_type(self, vuln_type: str) -> str:
        """Get CWE ID for vulnerability type"""

        cwe_mapping = {
            'sql_injection': 'CWE-89',
            'xss': 'CWE-79',
            'command_injection': 'CWE-78',
            'hardcoded_secrets': 'CWE-798',
            'code_injection': 'CWE-94'
        }

        return cwe_mapping.get(vuln_type, 'CWE-200')

    async def analyze_project_directory(self, directory_path: str) -> Dict[str, Any]:
        """Analyze entire project directory"""

        results = {
            'timestamp': datetime.now().isoformat(),
            'directory_path': directory_path,
            'findings': [],
            'files_analyzed': 0,
            'vulnerability_score': 0.0
        }

        all_findings = []

        # Analyze code files
        for root, dirs, files in os.walk(directory_path):
            for file in files:
                if file.endswith(('.py', '.js', '.java', '.php', '.rb', '.go')):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()

                        file_results = await self.analyze_code_snippet(content, file_path)
                        all_findings.extend([AIFinding(**f) for f in file_results['findings']])
                        results['files_analyzed'] += 1

                    except Exception as e:
                        logger.error(f"Failed to analyze {file_path}: {e}")

        # Calculate overall score
        if all_findings:
            scores = [f.confidence_score for f in all_findings]
            results['vulnerability_score'] = sum(scores) / len(scores)

        results['findings'] = [asdict(finding) for finding in all_findings]

        return results

    async def analyze_web_application(self, url: str) -> Dict[str, Any]:
        """Analyze web application for AI-detectable patterns"""

        results = {
            'timestamp': datetime.now().isoformat(),
            'target_url': url,
            'findings': [],
            'vulnerability_score': 0.0
        }

        # This would integrate with web crawling and content analysis
        # For now, return placeholder results
        finding = AIFinding(
            id="AI-WEB-001",
            title="Web Application AI Analysis",
            severity="INFO",
            confidence="Low",
            description="AI analysis placeholder for web application",
            impact="Informational finding",
            recommendation="Implement comprehensive AI-based web analysis",
            vulnerability_type="web_analysis",
            confidence_score=0.1,
            model_used="placeholder"
        )

        results['findings'] = [asdict(finding)]
        return results

    async def analyze_mobile_application(self, app_path: str) -> Dict[str, Any]:
        """Analyze mobile application using AI"""

        results = {
            'timestamp': datetime.now().isoformat(),
            'app_path': app_path,
            'findings': [],
            'vulnerability_score': 0.0
        }

        # Placeholder for mobile AI analysis
        finding = AIFinding(
            id="AI-MOBILE-001",
            title="Mobile Application AI Analysis",
            severity="INFO",
            confidence="Low",
            description="AI analysis placeholder for mobile application",
            impact="Informational finding",
            recommendation="Implement comprehensive AI-based mobile analysis",
            vulnerability_type="mobile_analysis",
            confidence_score=0.1,
            model_used="placeholder"
        )

        results['findings'] = [asdict(finding)]
        return results

    async def analyze_binary_file(self, binary_path: str) -> Dict[str, Any]:
        """Analyze binary file using AI/ML models"""

        results = {
            'timestamp': datetime.now().isoformat(),
            'binary_path': binary_path,
            'findings': [],
            'vulnerability_score': 0.0,
            'binary_info': {},
            'ml_analysis': {},
            'pattern_analysis': {}
        }

        try:
            logger.info(f"Starting AI analysis of binary: {binary_path}")

            # Initialize models if not already done
            if not self.models:
                await self.initialize_models()

            findings = []

            # 1. Extract binary metadata and strings
            binary_data = await self._extract_binary_features(binary_path)
            results['binary_info'] = binary_data

            # 2. Analyze with traditional ML models
            if 'binary_classifier' in self.models:
                ml_findings = await self._analyze_binary_with_ml(binary_data, binary_path)
                findings.extend(ml_findings)

            # 3. Pattern-based analysis on disassembly
            pattern_findings = await self._analyze_binary_patterns(binary_data, binary_path)
            findings.extend(pattern_findings)

            # 4. String-based analysis
            string_findings = await self._analyze_binary_strings(binary_data, binary_path)
            findings.extend(string_findings)

            # 5. Import/export analysis
            import_findings = await self._analyze_binary_imports(binary_data, binary_path)
            findings.extend(import_findings)

            # 6. Deep learning analysis (if available)
            if TRANSFORMERS_AVAILABLE and 'transformer' in self.models:
                dl_findings = await self._analyze_binary_with_transformers(binary_data, binary_path)
                findings.extend(dl_findings)

            # Calculate overall vulnerability score
            if findings:
                # Weight findings by confidence and severity
                total_score = 0.0
                for finding in findings:
                    severity_weight = {
                        'CRITICAL': 1.0, 'HIGH': 0.8, 'MEDIUM': 0.6, 'LOW': 0.4, 'INFO': 0.2
                    }.get(finding.severity, 0.3)
                    total_score += finding.confidence_score * severity_weight

                results['vulnerability_score'] = min(total_score / len(findings), 1.0)
            else:
                results['vulnerability_score'] = 0.0

            # Convert findings to dict format
            results['findings'] = [asdict(finding) for finding in findings]
            results['ml_analysis'] = {
                'models_used': list(self.models.keys()),
                'total_findings': len(findings),
                'high_confidence_findings': len([f for f in findings if f.confidence_score > 0.7])
            }

            logger.info(f"Binary AI analysis completed: {len(findings)} findings")

        except Exception as e:
            logger.error(f"Binary AI analysis failed: {e}")
            results['error'] = str(e)

        return results

    async def _extract_binary_features(self, binary_path: str) -> Dict[str, Any]:
        """Extract comprehensive features from binary for ML analysis"""

        features = {
            'file_size': 0,
            'strings': [],
            'imports': [],
            'exports': [],
            'sections': [],
            'disassembly': [],
            'entropy': 0.0,
            'file_type': 'unknown',
            'architecture': 'unknown',
            'packed': False,
            'signed': False,
            'security_features': {},
            'metadata': {}
        }

        try:
            # Basic file info
            if os.path.exists(binary_path):
                features['file_size'] = os.path.getsize(binary_path)

            # Use enhanced binary analysis if available
            try:
                from security_engines.binary.enhanced_binary_engine import EnhancedBinaryEngine

                # Quick metadata extraction
                engine = EnhancedBinaryEngine()
                metadata = await engine._extract_metadata(binary_path)

                features.update({
                    'file_type': metadata.format.value if hasattr(metadata.format, 'value') else str(metadata.format),
                    'architecture': metadata.architecture.value if hasattr(metadata.architecture, 'value') else str(metadata.architecture),
                    'entropy': metadata.entropy,
                    'packed': metadata.packed,
                    'signed': metadata.signed,
                    'strings': metadata.strings[:500],  # First 500 strings
                    'imports': metadata.imports[:200],   # First 200 imports
                    'exports': metadata.exports[:200],   # First 200 exports
                    'sections': [{'name': s.get('name', ''), 'size': s.get('size', 0)} for s in metadata.sections[:50]]
                })

                features['metadata'] = {
                    'entry_point': metadata.entry_point,
                    'debug_info': metadata.debug_info,
                    'stripped': metadata.stripped
                }

                return features

            except ImportError:
                logger.info("Enhanced binary engine not available, using basic extraction")
                pass

            # Fallback: Basic feature extraction using system tools
            await self._extract_basic_binary_features(binary_path, features)

        except Exception as e:
            logger.error(f"Binary feature extraction failed: {e}")

        return features

    async def _extract_basic_binary_features(self, binary_path: str, features: Dict[str, Any]):
        """Extract basic binary features using system tools"""
        try:
            import subprocess

            # File type detection
            try:
                result = subprocess.run(['file', binary_path], capture_output=True, text=True, timeout=10)
                if result.returncode == 0:
                    file_output = result.stdout.lower()
                    features['file_type'] = file_output.strip()

                    # Detect architecture
                    if 'x86-64' in file_output or 'amd64' in file_output:
                        features['architecture'] = 'x86_64'
                    elif 'i386' in file_output or '80386' in file_output:
                        features['architecture'] = 'x86'
                    elif 'arm64' in file_output or 'aarch64' in file_output:
                        features['architecture'] = 'arm64'
                    elif 'arm' in file_output:
                        features['architecture'] = 'arm'

            except Exception:
                pass

            # Extract strings
            try:
                result = subprocess.run(['strings', '-n', '4', binary_path], capture_output=True, text=True, timeout=30)
                if result.returncode == 0:
                    strings_list = result.stdout.strip().split('\n')
                    features['strings'] = [s for s in strings_list[:500] if s.strip()]
            except Exception:
                # Fallback: Extract strings manually
                try:
                    with open(binary_path, 'rb') as f:
                        data = f.read(1024*1024)  # First 1MB

                    # Simple string extraction
                    import re
                    strings = re.findall(rb'[\x20-\x7E]{4,}', data)
                    features['strings'] = [s.decode('ascii', errors='ignore') for s in strings[:200]]
                except Exception:
                    pass

            # Calculate basic entropy
            try:
                with open(binary_path, 'rb') as f:
                    data = f.read(1024)  # First 1KB

                if data:
                    from collections import Counter
                    import math

                    counter = Counter(data)
                    length = len(data)
                    entropy = 0.0

                    for count in counter.values():
                        probability = count / length
                        if probability > 0:
                            entropy -= probability * math.log2(probability)

                    features['entropy'] = entropy
                    features['packed'] = entropy > 7.5

            except Exception:
                pass

        except Exception as e:
            logger.error(f"Basic binary feature extraction failed: {e}")

    async def _analyze_binary_with_ml(self, binary_data: Dict[str, Any], binary_path: str) -> List[AIFinding]:
        """Analyze binary using ML models"""
        findings = []

        try:
            if 'binary_classifier' not in self.models or 'binary_vectorizer' not in self.models:
                return findings

            # Combine strings for analysis
            text_features = []
            text_features.extend(binary_data.get('strings', []))
            text_features.extend(binary_data.get('imports', []))
            text_features.extend(binary_data.get('exports', []))

            if not text_features:
                return findings

            # Prepare text for ML analysis
            combined_text = ' '.join(text_features)

            # Vectorize the text
            vectorizer = self.models['binary_vectorizer']
            classifier = self.models['binary_classifier']

            text_vector = vectorizer.transform([combined_text])

            # Get prediction and confidence
            prediction = classifier.predict(text_vector)[0]
            probabilities = classifier.predict_proba(text_vector)[0]
            confidence = max(probabilities)

            # Create finding if vulnerability detected
            if prediction != 'safe_code' and confidence > 0.3:
                finding = AIFinding(
                    id=f"ML-{len(findings)+1:03d}",
                    title=f"ML Detected: {prediction.replace('_', ' ').title()}",
                    severity=self._map_vulnerability_to_severity(prediction),
                    confidence=self._map_confidence_score(confidence),
                    description=f"Machine learning model detected potential {prediction} in binary analysis",
                    impact=self._get_vulnerability_impact(prediction),
                    recommendation=self._get_vulnerability_recommendation(prediction),
                    vulnerability_type=prediction,
                    confidence_score=confidence,
                    model_used="RandomForest Binary Classifier"
                )

                # Map to CWE if available
                if self.owasp_cwe_mapper:
                    cwe_mapping = await self.owasp_cwe_mapper.map_vulnerability_to_cwe(
                        prediction, combined_text[:200], confidence
                    )
                    if cwe_mapping:
                        finding.cwe_id = cwe_mapping.cwe_id

                findings.append(finding)

        except Exception as e:
            logger.error(f"ML binary analysis failed: {e}")

        return findings

    async def _analyze_binary_patterns(self, binary_data: Dict[str, Any], binary_path: str) -> List[AIFinding]:
        """Analyze binary using pattern matching"""
        findings = []

        try:
            strings = binary_data.get('strings', [])
            imports = binary_data.get('imports', [])

            # Check for dangerous function patterns
            dangerous_patterns = {
                'buffer_overflow': ['strcpy', 'strcat', 'sprintf', 'gets', 'scanf'],
                'format_string': ['printf', 'fprintf', 'syslog'],
                'memory_corruption': ['malloc', 'free', 'realloc', 'calloc'],
                'command_injection': ['system', 'exec', 'popen', 'shell'],
                'weak_crypto': ['MD5', 'SHA1', 'DES', 'RC4'],
                'privilege_escalation': ['setuid', 'seteuid', 'setgid', 'sudo']
            }

            all_text = ' '.join(strings + imports).lower()

            for vuln_type, patterns in dangerous_patterns.items():
                matches = []
                for pattern in patterns:
                    if pattern.lower() in all_text:
                        matches.append(pattern)

                if matches:
                    confidence = min(0.9, len(matches) * 0.2 + 0.3)

                    finding = AIFinding(
                        id=f"PAT-{len(findings)+1:03d}",
                        title=f"Pattern Analysis: {vuln_type.replace('_', ' ').title()}",
                        severity=self._map_vulnerability_to_severity(vuln_type),
                        confidence=self._map_confidence_score(confidence),
                        description=f"Pattern analysis detected {vuln_type} indicators in binary",
                        impact=self._get_vulnerability_impact(vuln_type),
                        recommendation=self._get_vulnerability_recommendation(vuln_type),
                        vulnerability_type=vuln_type,
                        confidence_score=confidence,
                        model_used="Pattern Matcher",
                        evidence=f"Detected patterns: {', '.join(matches[:5])}"
                    )
                    findings.append(finding)

        except Exception as e:
            logger.error(f"Pattern analysis failed: {e}")

        return findings

    async def _analyze_binary_strings(self, binary_data: Dict[str, Any], binary_path: str) -> List[AIFinding]:
        """Analyze binary strings for suspicious content"""
        findings = []

        try:
            strings = binary_data.get('strings', [])

            # Suspicious string patterns
            suspicious_patterns = {
                'hardcoded_credentials': [r'password\s*=', r'passwd\s*=', r'admin\s*=', r'key\s*='],
                'network_backdoor': [r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+', r'http://.*', r'ftp://.*'],
                'malware_indicators': [r'trojan', r'rootkit', r'backdoor', r'malware', r'virus'],
                'anti_analysis': [r'debugger', r'ollydbg', r'ida', r'ghidra', r'radare'],
                'data_exfiltration': [r'keylog', r'screenshot', r'webcam', r'microphone']
            }

            for vuln_type, patterns in suspicious_patterns.items():
                matches = []
                for string in strings:
                    for pattern in patterns:
                        if re.search(pattern, string, re.IGNORECASE):
                            matches.append(string)

                if matches:
                    confidence = min(0.85, len(matches) * 0.15 + 0.4)

                    finding = AIFinding(
                        id=f"STR-{len(findings)+1:03d}",
                        title=f"String Analysis: {vuln_type.replace('_', ' ').title()}",
                        severity=self._map_vulnerability_to_severity(vuln_type),
                        confidence=self._map_confidence_score(confidence),
                        description=f"Suspicious strings detected indicating {vuln_type}",
                        impact=self._get_vulnerability_impact(vuln_type),
                        recommendation=self._get_vulnerability_recommendation(vuln_type),
                        vulnerability_type=vuln_type,
                        confidence_score=confidence,
                        model_used="String Analyzer",
                        evidence=f"Suspicious strings: {matches[:3]}"
                    )
                    findings.append(finding)

        except Exception as e:
            logger.error(f"String analysis failed: {e}")

        return findings

    async def _analyze_binary_imports(self, binary_data: Dict[str, Any], binary_path: str) -> List[AIFinding]:
        """Analyze binary imports for security implications"""
        findings = []

        try:
            imports = binary_data.get('imports', [])

            # Suspicious import patterns
            suspicious_imports = {
                'process_manipulation': ['CreateProcess', 'OpenProcess', 'TerminateProcess', 'WriteProcessMemory'],
                'registry_manipulation': ['RegCreateKey', 'RegSetValue', 'RegDeleteKey', 'RegOpenKey'],
                'file_manipulation': ['CreateFile', 'DeleteFile', 'MoveFile', 'CopyFile'],
                'network_operations': ['WSAStartup', 'socket', 'connect', 'send', 'recv', 'InternetOpen'],
                'crypto_operations': ['CryptCreateHash', 'CryptEncrypt', 'CryptDecrypt'],
                'debug_evasion': ['IsDebuggerPresent', 'CheckRemoteDebuggerPresent', 'OutputDebugString']
            }

            all_imports = ' '.join(imports).lower()

            for category, import_list in suspicious_imports.items():
                detected_imports = []
                for imp in import_list:
                    if imp.lower() in all_imports:
                        detected_imports.append(imp)

                if detected_imports:
                    # Calculate confidence based on number and type of imports
                    confidence = min(0.8, len(detected_imports) * 0.1 + 0.3)

                    finding = AIFinding(
                        id=f"IMP-{len(findings)+1:03d}",
                        title=f"Import Analysis: {category.replace('_', ' ').title()}",
                        severity=self._map_import_category_to_severity(category),
                        confidence=self._map_confidence_score(confidence),
                        description=f"Binary imports functions related to {category}",
                        impact=self._get_import_category_impact(category),
                        recommendation=self._get_import_category_recommendation(category),
                        vulnerability_type=category,
                        confidence_score=confidence,
                        model_used="Import Analyzer",
                        evidence=f"Detected imports: {', '.join(detected_imports[:5])}"
                    )
                    findings.append(finding)

        except Exception as e:
            logger.error(f"Import analysis failed: {e}")

        return findings

    async def _analyze_binary_with_transformers(self, binary_data: Dict[str, Any], binary_path: str) -> List[AIFinding]:
        """Analyze binary using transformer models"""
        findings = []

        try:
            if 'transformer' not in self.models:
                return findings

            # Prepare text for transformer analysis
            text_features = []
            text_features.extend(binary_data.get('strings', [])[:100])  # First 100 strings
            text_features.extend(binary_data.get('imports', [])[:50])   # First 50 imports

            if not text_features:
                return findings

            combined_text = ' '.join(text_features)[:512]  # Transformer input limit

            # Use transformer model
            transformer = self.models['transformer']
            results = transformer(combined_text)

            # Process transformer results
            for result in results:
                if result['label'] == 'NEGATIVE' and result['score'] > 0.7:
                    finding = AIFinding(
                        id=f"DL-{len(findings)+1:03d}",
                        title="Deep Learning: Suspicious Binary Content",
                        severity="MEDIUM",
                        confidence="Medium",
                        description="Deep learning model detected suspicious patterns in binary content",
                        impact="Binary may contain malicious or vulnerable code patterns",
                        recommendation="Review binary content and functionality for security issues",
                        vulnerability_type="suspicious_content",
                        confidence_score=result['score'],
                        model_used="DistilBERT Transformer"
                    )
                    findings.append(finding)

        except Exception as e:
            logger.error(f"Transformer analysis failed: {e}")

        return findings

    def _map_vulnerability_to_severity(self, vuln_type: str) -> str:
        """Map vulnerability type to severity level"""
        severity_map = {
            'buffer_overflow': 'HIGH',
            'format_string': 'HIGH',
            'command_injection': 'CRITICAL',
            'code_injection': 'CRITICAL',
            'privilege_escalation': 'CRITICAL',
            'memory_corruption': 'HIGH',
            'weak_crypto': 'MEDIUM',
            'hardcoded_credentials': 'HIGH',
            'network_backdoor': 'CRITICAL',
            'malware_indicators': 'CRITICAL',
            'anti_analysis': 'MEDIUM',
            'data_exfiltration': 'HIGH'
        }
        return severity_map.get(vuln_type, 'MEDIUM')

    def _map_import_category_to_severity(self, category: str) -> str:
        """Map import category to severity level"""
        severity_map = {
            'process_manipulation': 'HIGH',
            'registry_manipulation': 'MEDIUM',
            'file_manipulation': 'MEDIUM',
            'network_operations': 'MEDIUM',
            'crypto_operations': 'LOW',
            'debug_evasion': 'MEDIUM'
        }
        return severity_map.get(category, 'LOW')

    def _get_vulnerability_impact(self, vuln_type: str) -> str:
        """Get impact description for vulnerability type"""
        impact_map = {
            'buffer_overflow': 'Potential memory corruption and code execution',
            'format_string': 'Information disclosure and potential code execution',
            'command_injection': 'Arbitrary command execution',
            'privilege_escalation': 'Unauthorized privilege elevation',
            'weak_crypto': 'Cryptographic security weakened',
            'hardcoded_credentials': 'Authentication bypass possible',
            'network_backdoor': 'Unauthorized network access',
            'malware_indicators': 'Potential malicious functionality'
        }
        return impact_map.get(vuln_type, 'Security risk identified')

    def _get_vulnerability_recommendation(self, vuln_type: str) -> str:
        """Get recommendation for vulnerability type"""
        recommendation_map = {
            'buffer_overflow': 'Use safe string functions and bounds checking',
            'format_string': 'Use proper format string handling',
            'command_injection': 'Sanitize input and avoid system calls',
            'privilege_escalation': 'Follow principle of least privilege',
            'weak_crypto': 'Use strong cryptographic algorithms',
            'hardcoded_credentials': 'Use secure credential management',
            'network_backdoor': 'Review network communication logic',
            'malware_indicators': 'Conduct thorough security review'
        }
        return recommendation_map.get(vuln_type, 'Review and address security concern')

    def _get_import_category_impact(self, category: str) -> str:
        """Get impact description for import category"""
        impact_map = {
            'process_manipulation': 'Can manipulate other processes',
            'registry_manipulation': 'Can modify system registry',
            'file_manipulation': 'Can manipulate filesystem',
            'network_operations': 'Can perform network communication',
            'crypto_operations': 'Uses cryptographic functions',
            'debug_evasion': 'May attempt to evade analysis'
        }
        return impact_map.get(category, 'Functional capability identified')

    def _get_import_category_recommendation(self, category: str) -> str:
        """Get recommendation for import category"""
        recommendation_map = {
            'process_manipulation': 'Verify legitimate need for process manipulation',
            'registry_manipulation': 'Ensure registry changes are necessary and safe',
            'file_manipulation': 'Validate file operations are secure',
            'network_operations': 'Review network communication for security',
            'crypto_operations': 'Verify cryptographic implementation',
            'debug_evasion': 'Investigate anti-analysis behavior'
        }
        return recommendation_map.get(category, 'Review functionality for security implications')

    def _calculate_entropy(self, data: bytes) -> float:
        """Calculate Shannon entropy of data"""
        try:
            from collections import Counter
            import math

            if not data:
                return 0.0

            counter = Counter(data)
            length = len(data)
            entropy = 0.0

            for count in counter.values():
                probability = count / length
                if probability > 0:
                    entropy -= probability * math.log2(probability)

            return entropy
        except Exception:
            return 0.0

    def _map_confidence_score(self, score: float) -> str:
        """Map numeric confidence score to string"""
        if score >= 0.8:
            return "High"
        elif score >= 0.6:
            return "Medium"
        elif score >= 0.4:
            return "Low"
        else:
            return "Very Low"

    async def _analyze_binary_with_ml(self, binary_data: Dict, binary_path: str) -> List[AIFinding]:
        """Analyze binary using traditional ML models"""
        findings = []

        try:
            if SKLEARN_AVAILABLE and 'binary_classifier' in self.models and 'binary_vectorizer' in self.models:
                # Analyze binary strings using the trained binary classifier
                strings = binary_data.get('strings', [])

                if strings:
                    # Combine strings for analysis
                    combined_text = ' '.join(strings[:200])  # Use first 200 strings

                    # Vectorize the text
                    vectorizer = self.models['binary_vectorizer']
                    text_vector = vectorizer.transform([combined_text])

                    # Get predictions
                    classifier = self.models['binary_classifier']
                    prediction = classifier.predict(text_vector)[0]
                    probabilities = classifier.predict_proba(text_vector)[0]
                    confidence = max(probabilities)

                    # Create finding if not safe and confidence is high enough
                    if prediction != 'safe_code' and confidence > 0.6:
                        finding = AIFinding(
                            id=f"AI-BIN-ML-{len(findings)+1:03d}",
                            title=f"ML-Detected Binary Vulnerability: {prediction.replace('_', ' ').title()}",
                            severity="HIGH" if confidence > 0.8 else "MEDIUM",
                            confidence="High" if confidence > 0.8 else "Medium",
                            description=f"Binary ML classifier detected potential {prediction.replace('_', ' ')} vulnerability",
                            impact="Binary may contain security vulnerabilities",
                            recommendation="Perform detailed analysis and apply security patches",
                            vulnerability_type=prediction,
                            confidence_score=confidence,
                            model_used="Binary Random Forest Classifier",
                            evidence=f"Analyzed {len(strings)} strings, file size: {binary_data.get('file_size', 0)} bytes"
                        )
                        findings.append(finding)

                # Also try feature-based analysis
                feature_vector = self._create_binary_feature_vector(binary_data)
                if feature_vector is not None and len(feature_vector) >= 7:
                    # Use feature vector for additional analysis
                    # This would require a separate feature-based model
                    # For now, we'll use it as additional evidence
                    high_entropy = binary_data.get('entropy', 0) > 7.5
                    large_file = binary_data.get('file_size', 0) > 10000000  # 10MB
                    many_strings = len(strings) > 500

                    if high_entropy and (large_file or many_strings):
                        finding = AIFinding(
                            id=f"AI-BIN-FEAT-{len(findings)+1:03d}",
                            title="Feature-Based Binary Analysis Alert",
                            severity="MEDIUM",
                            confidence="Medium",
                            description="Binary exhibits characteristics often associated with packed or obfuscated code",
                            impact="May indicate obfuscation, packing, or malicious content",
                            recommendation="Analyze binary for packing, obfuscation, or malicious behavior",
                            vulnerability_type="suspicious_characteristics",
                            confidence_score=0.7,
                            model_used="Feature Analyzer",
                            evidence=f"Entropy: {binary_data.get('entropy', 0):.2f}, Size: {binary_data.get('file_size', 0)}, Strings: {len(strings)}"
                        )
                        findings.append(finding)

        except Exception as e:
            logger.error(f"ML binary analysis failed: {e}")

        return findings

    def _create_binary_feature_vector(self, binary_data: Dict) -> Optional[List[float]]:
        """Create numerical feature vector from binary data"""
        try:
            features = []

            # File size (normalized)
            file_size = binary_data.get('file_size', 0)
            features.append(min(file_size / 1000000, 10))  # Size in MB, capped at 10

            # Entropy
            features.append(binary_data.get('entropy', 0))

            # String count
            strings = binary_data.get('strings', [])
            features.append(min(len(strings) / 100, 10))  # Normalized string count

            # Dangerous string patterns
            dangerous_patterns = ['system', 'exec', 'shell', 'cmd', 'password', 'admin', 'root']
            dangerous_count = sum(1 for s in strings if any(p in s.lower() for p in dangerous_patterns))
            features.append(min(dangerous_count / 10, 5))

            # URL patterns in strings
            url_count = sum(1 for s in strings if 'http' in s.lower() or 'ftp' in s.lower())
            features.append(min(url_count / 5, 3))

            # Import count
            imports = binary_data.get('imports', [])
            features.append(min(len(imports) / 50, 5))

            # File type encoding
            file_type = binary_data.get('file_type', 'unknown')
            type_encoding = {'PE': 1, 'ELF': 2, 'Mach-O': 3, 'unknown': 0}.get(file_type, 0)
            features.append(type_encoding)

            return features

        except Exception as e:
            logger.error(f"Feature vector creation failed: {e}")
            return None

    async def _analyze_binary_patterns(self, binary_data: Dict, binary_path: str) -> List[AIFinding]:
        """Analyze binary using assembly/disassembly patterns"""
        findings = []

        try:
            # Analyze strings for known vulnerability patterns
            strings = binary_data.get('strings', [])

            for vuln_type, patterns in self.asm_patterns.items():
                for pattern in patterns:
                    pattern_matches = 0
                    evidence_strings = []

                    for s in strings:
                        if re.search(pattern, s, re.IGNORECASE):
                            pattern_matches += 1
                            evidence_strings.append(s[:50])

                    if pattern_matches > 0:
                        confidence = min(pattern_matches / 10.0, 1.0)

                        finding = AIFinding(
                            id=f"AI-BIN-PAT-{len(findings)+1:03d}",
                            title=f"Pattern-Detected Binary Vulnerability: {vuln_type}",
                            severity="HIGH" if confidence > 0.7 else "MEDIUM" if confidence > 0.4 else "LOW",
                            confidence="High" if confidence > 0.7 else "Medium" if confidence > 0.4 else "Low",
                            description=f"Assembly pattern analysis detected potential {vuln_type} vulnerability",
                            impact="Binary may be vulnerable to exploitation",
                            recommendation="Review assembly code and apply appropriate mitigations",
                            vulnerability_type=vuln_type,
                            confidence_score=confidence,
                            model_used="Pattern Matcher",
                            evidence=f"Pattern matches: {pattern_matches}, Examples: {', '.join(evidence_strings[:3])}"
                        )
                        findings.append(finding)

        except Exception as e:
            logger.error(f"Pattern analysis failed: {e}")

        return findings

    async def _analyze_binary_strings(self, binary_data: Dict, binary_path: str) -> List[AIFinding]:
        """Analyze binary strings for security issues"""
        findings = []

        try:
            strings = binary_data.get('strings', [])

            # Define string-based vulnerability patterns
            string_patterns = {
                'hardcoded_credentials': [
                    r'password\s*[:=]\s*["\']?\w{4,}["\']?',
                    r'admin\s*[:=]\s*["\']?\w{4,}["\']?',
                    r'root\s*[:=]\s*["\']?\w{4,}["\']?',
                    r'api[_-]?key\s*[:=]\s*["\']?[a-zA-Z0-9]{16,}["\']?'
                ],
                'weak_crypto': [
                    r'MD5', r'SHA1', r'DES', r'RC4',
                    r'md5sum', r'sha1sum'
                ],
                'command_injection': [
                    r'system\s*\(', r'exec\s*\(', r'popen\s*\(',
                    r'sh\s+-c', r'cmd\s+/c', r'powershell'
                ],
                'insecure_network': [
                    r'http://[^/\s]+', r'ftp://[^/\s]+',
                    r'telnet://', r'ldap://'
                ],
                'debug_info': [
                    r'debug', r'trace', r'verbose', r'test',
                    r'development', r'staging'
                ]
            }

            for vuln_type, patterns in string_patterns.items():
                matches = []
                for s in strings:
                    for pattern in patterns:
                        if re.search(pattern, s, re.IGNORECASE):
                            matches.append(s[:100])

                if matches:
                    confidence = min(len(matches) / 20.0, 1.0)

                    finding = AIFinding(
                        id=f"AI-BIN-STR-{len(findings)+1:03d}",
                        title=f"String Analysis Detected: {vuln_type}",
                        severity="MEDIUM" if vuln_type in ['hardcoded_credentials', 'weak_crypto'] else "LOW",
                        confidence="Medium" if confidence > 0.5 else "Low",
                        description=f"String analysis detected potential {vuln_type} in binary",
                        impact="Binary may contain security issues",
                        recommendation="Review and remove sensitive information from binary",
                        vulnerability_type=vuln_type,
                        confidence_score=confidence,
                        model_used="String Pattern Analyzer",
                        evidence=f"Found {len(matches)} matches: {matches[0] if matches else 'N/A'}"
                    )
                    findings.append(finding)

        except Exception as e:
            logger.error(f"String analysis failed: {e}")

        return findings

    async def _analyze_binary_imports(self, binary_data: Dict, binary_path: str) -> List[AIFinding]:
        """Analyze binary imports for dangerous functions"""
        findings = []

        try:
            imports = binary_data.get('imports', [])

            # Dangerous function imports
            dangerous_imports = {
                'buffer_overflow': ['strcpy', 'strcat', 'sprintf', 'gets', 'scanf'],
                'command_injection': ['system', 'exec', 'popen', 'CreateProcess'],
                'privilege_escalation': ['setuid', 'seteuid', 'setreuid', 'ImpersonateLoggedOnUser'],
                'network_security': ['socket', 'connect', 'send', 'recv', 'WinHttpOpen'],
                'crypto_weak': ['MD5_Init', 'SHA1_Init', 'DES_encrypt', 'RC4_set_key']
            }

            for vuln_type, func_list in dangerous_imports.items():
                found_functions = []
                for imp in imports:
                    for func in func_list:
                        if func.lower() in imp.lower():
                            found_functions.append(imp)

                if found_functions:
                    confidence = min(len(found_functions) / 10.0, 1.0)

                    finding = AIFinding(
                        id=f"AI-BIN-IMP-{len(findings)+1:03d}",
                        title=f"Dangerous Import Detected: {vuln_type}",
                        severity="HIGH" if vuln_type in ['buffer_overflow', 'command_injection'] else "MEDIUM",
                        confidence="High" if confidence > 0.6 else "Medium",
                        description=f"Binary imports potentially dangerous functions related to {vuln_type}",
                        impact="Binary may be vulnerable to exploitation via imported functions",
                        recommendation="Review function usage and implement proper input validation",
                        vulnerability_type=vuln_type,
                        confidence_score=confidence,
                        model_used="Import Analyzer",
                        evidence=f"Dangerous imports: {', '.join(found_functions[:5])}"
                    )
                    findings.append(finding)

        except Exception as e:
            logger.error(f"Import analysis failed: {e}")

        return findings

    async def _analyze_binary_with_transformers(self, binary_data: Dict, binary_path: str) -> List[AIFinding]:
        """Analyze binary using transformer models"""
        findings = []

        try:
            if 'transformer' in self.models:
                # Use transformer on extracted strings
                strings = binary_data.get('strings', [])

                # Combine relevant strings for analysis
                combined_text = ' '.join(strings[:100])  # First 100 strings

                if combined_text and len(combined_text) > 50:
                    classifier = self.models['transformer']
                    results = classifier(combined_text)

                    for result in results:
                        if result['label'] == 'NEGATIVE' and result['score'] > 0.7:
                            finding = AIFinding(
                                id=f"AI-BIN-TRANS-{len(findings)+1:03d}",
                                title="Transformer Detected Binary Security Issue",
                                severity="MEDIUM",
                                confidence="Medium",
                                description="Deep learning model detected potential security concerns in binary strings",
                                impact="Binary may contain security vulnerabilities",
                                recommendation="Perform detailed security review",
                                vulnerability_type="ml_detected",
                                confidence_score=result['score'],
                                model_used="DistilBERT Transformer",
                                evidence=combined_text[:200]
                            )
                            findings.append(finding)

        except Exception as e:
            logger.error(f"Transformer binary analysis failed: {e}")

        return findings

    async def _enhance_findings_with_comprehensive_mappings(self, findings: List[AIFinding], code: str) -> List[Dict[str, Any]]:
        """Enhance findings with comprehensive CWE/SANS/OWASP mappings"""

        try:
            enhanced_findings = []

            for finding in findings:
                # Convert finding to dict if it's an AIFinding object
                if isinstance(finding, AIFinding):
                    finding_dict = asdict(finding)
                else:
                    finding_dict = finding

                # Extract vulnerability type and determine CWE mapping
                vuln_type = finding_dict.get('vulnerability_type', '')

                # Try to extract CWE from vulnerability type
                cwe_id = None
                if 'cwe_' in vuln_type.lower():
                    # Extract CWE ID from type like "cwe_79_xss"
                    import re
                    cwe_match = re.search(r'cwe[_-](\d+)', vuln_type.lower())
                    if cwe_match:
                        cwe_id = f"CWE-{cwe_match.group(1)}"

                # Get comprehensive vulnerability information
                vuln_info = None
                if cwe_id and self.vuln_mapper:
                    vuln_info = self.vuln_mapper.get_vulnerability_info(cwe_id)
                elif self.vuln_mapper:
                    # Try to find by vulnerability name/type
                    vuln_info = self.vuln_mapper.get_vulnerability_info(vuln_type)

                # Enhance finding with comprehensive information
                if vuln_info:
                    finding_dict['cwe_id'] = vuln_info.cwe_id
                    finding_dict['cwe_name'] = vuln_info.cwe_name
                    finding_dict['severity'] = vuln_info.severity
                    finding_dict['owasp_categories'] = vuln_info.owasp_categories
                    finding_dict['sans_rank'] = vuln_info.sans_rank
                    finding_dict['mitigation'] = vuln_info.mitigation
                    finding_dict['related_cves'] = vuln_info.related_cves
                    finding_dict['examples'] = vuln_info.examples

                    # Update confidence based on pattern matching
                    if finding_dict.get('confidence_score', 0) < 0.8:
                        # Check if code matches known patterns
                        patterns = vuln_info.detection_patterns
                        import re
                        for pattern in patterns:
                            try:
                                if re.search(pattern, code, re.IGNORECASE):
                                    finding_dict['confidence_score'] = min(
                                        finding_dict.get('confidence_score', 0.5) + 0.2,
                                        0.9
                                    )
                                    break
                            except re.error:
                                continue  # Skip invalid patterns

                # Add framework classifications
                framework_classifications = self._classify_vulnerability_frameworks(vuln_type, finding_dict)
                finding_dict.update(framework_classifications)

                enhanced_findings.append(finding_dict)

            return enhanced_findings

        except Exception as e:
            logger.error(f"Failed to enhance findings with comprehensive mappings: {e}")
            # Return original findings as fallback
            return [asdict(f) if isinstance(f, AIFinding) else f for f in findings]

    def _classify_vulnerability_frameworks(self, vuln_type: str, finding_dict: Dict[str, Any]) -> Dict[str, Any]:
        """Classify vulnerability according to different security frameworks"""

        classifications = {
            'framework_classifications': {
                'cwe_top_25': False,
                'sans_top_25': False,
                'owasp_web_top_10': False,
                'owasp_mobile_top_10': False,
                'owasp_api_top_10': False,
                'owasp_serverless_top_10': False,
                'kernel_vulnerability': False,
                'binary_vulnerability': False
            }
        }

        vuln_lower = vuln_type.lower()

        # CWE Top 25 classification
        if any(cwe in vuln_lower for cwe in ['cwe_787', 'cwe_79', 'cwe_89', 'cwe_416', 'cwe_78',
                                            'cwe_20', 'cwe_125', 'cwe_22', 'cwe_352', 'cwe_434']):
            classifications['framework_classifications']['cwe_top_25'] = True

        # SANS Top 25 classification
        if any(sans in vuln_lower for sans in ['buffer_overflow', 'xss', 'sql_injection', 'command_injection']):
            classifications['framework_classifications']['sans_top_25'] = True

        # OWASP Web Top 10 classification
        if any(owasp in vuln_lower for owasp in ['injection', 'broken_auth', 'cryptographic_failure',
                                                'insecure_design', 'security_misconfiguration']):
            classifications['framework_classifications']['owasp_web_top_10'] = True

        # OWASP Mobile Top 10 classification
        if 'mobile_' in vuln_lower or any(mobile in vuln_lower for mobile in ['platform_usage', 'insecure_storage',
                                                                             'insecure_communication', 'weak_crypto']):
            classifications['framework_classifications']['owasp_mobile_top_10'] = True

        # OWASP API Top 10 classification
        if 'api_' in vuln_lower or any(api in vuln_lower for api in ['broken_object_authz', 'mass_assignment',
                                                                    'excessive_data_exposure', 'lack_resources_limiting']):
            classifications['framework_classifications']['owasp_api_top_10'] = True

        # OWASP Serverless Top 10 classification
        if 'serverless_' in vuln_lower or any(serverless in vuln_lower for serverless in ['overprivileged', 'insecure_deployment',
                                                                                         'inadequate_monitoring', 'dependency_vulnerabilities']):
            classifications['framework_classifications']['owasp_serverless_top_10'] = True

        # Kernel vulnerability classification
        if 'kernel_' in vuln_lower or any(kernel in vuln_lower for kernel in ['syscall', 'rootkit', 'privilege_escalation',
                                                                             'memory_corruption', 'user_copy']):
            classifications['framework_classifications']['kernel_vulnerability'] = True

        # Binary vulnerability classification
        if 'binary_' in vuln_lower or any(binary in vuln_lower for binary in ['rop_gadget', 'shellcode', 'nop_sled',
                                                                             'anti_debug', 'packing', 'suspicious_entropy']):
            classifications['framework_classifications']['binary_vulnerability'] = True

        # Add severity mapping based on framework
        if classifications['framework_classifications']['cwe_top_25']:
            finding_dict['severity_level'] = 'HIGH'
        elif classifications['framework_classifications']['kernel_vulnerability']:
            finding_dict['severity_level'] = 'CRITICAL'
        elif classifications['framework_classifications']['binary_vulnerability']:
            finding_dict['severity_level'] = 'HIGH'
        else:
            finding_dict['severity_level'] = finding_dict.get('severity', 'MEDIUM')

        return classifications

    async def _analyze_with_kernel_engine(self, code: str, file_path: str) -> List[Dict[str, Any]]:
        """Analyze code using kernel vulnerability engine"""

        try:
            findings = []

            # Initialize kernel engine if not already done
            if not self.kernel_engine and KERNEL_ENGINE_AVAILABLE:
                from security_engines.kernel.kernel_vuln_engine import KernelVulnEngine
                self.kernel_engine = KernelVulnEngine(enable_dynamic=False)

            if not self.kernel_engine:
                return findings

            # Check if this is a kernel module file
            if not any(ext in file_path.lower() for ext in ['.ko', '.sys', '.kext', '.c', '.h']):
                return findings

            # Perform kernel-specific pattern analysis
            kernel_patterns = {
                'buffer_overflow': [
                    r'strcpy\s*\(',
                    r'strcat\s*\(',
                    r'sprintf\s*\(',
                    r'gets\s*\(',
                    r'copy_from_user\s*\([^,]+,\s*[^,]+,\s*[^)]+\)'
                ],
                'use_after_free': [
                    r'kfree\s*\(\s*\w+\s*\).*\w+\s*->',
                    r'vfree\s*\(\s*\w+\s*\).*\w+\s*\[',
                    r'free\s*\(\s*\w+\s*\).*\w+\s*->'
                ],
                'privilege_escalation': [
                    r'commit_creds\s*\(',
                    r'prepare_kernel_cred\s*\(',
                    r'override_cred\s*\(',
                    r'setuid\s*\(\s*0\s*\)'
                ],
                'syscall_hooking': [
                    r'sys_call_table\s*\[',
                    r'original_sys_\w+',
                    r'hijack_syscall',
                    r'hook_sys_\w+'
                ],
                'rootkit_behavior': [
                    r'hide_process\s*\(',
                    r'hide_file\s*\(',
                    r'hide_module\s*\(',
                    r'invisible_\w+'
                ]
            }

            import re
            finding_id = 1

            for category, patterns in kernel_patterns.items():
                for pattern in patterns:
                    try:
                        matches = re.finditer(pattern, code, re.IGNORECASE | re.MULTILINE)

                        for match in matches:
                            line_num = code[:match.start()].count('\n') + 1

                            # Map to CWE if possible
                            cwe_mapping = {
                                'buffer_overflow': 'CWE-787',
                                'use_after_free': 'CWE-416',
                                'privilege_escalation': 'CWE-269',
                                'syscall_hooking': 'CWE-506',
                                'rootkit_behavior': 'CWE-506'
                            }

                            finding = {
                                'id': f'KERN-AI-{finding_id:04d}',
                                'title': f'Kernel {category.replace("_", " ").title()} Detected',
                                'severity': 'HIGH' if category in ['use_after_free', 'privilege_escalation'] else 'MEDIUM',
                                'confidence': 'High',
                                'description': f'Kernel-specific {category} pattern detected in code',
                                'impact': f'Potential {category} vulnerability in kernel space',
                                'recommendation': f'Review and fix {category} issue',
                                'vulnerability_type': f'kernel_{category}',
                                'confidence_score': 0.85,
                                'model_used': 'kernel_pattern_analysis',
                                'evidence': match.group(0),
                                'cwe_id': cwe_mapping.get(category),
                                'line_number': line_num,
                                'framework_classifications': {
                                    'kernel_vulnerability': True,
                                    'cwe_top_25': category in ['buffer_overflow', 'use_after_free']
                                }
                            }

                            findings.append(finding)
                            finding_id += 1

                    except re.error:
                        continue  # Skip invalid patterns

            return findings

        except Exception as e:
            logger.error(f"Kernel engine analysis failed: {e}")
            return []

    async def analyze_comprehensive_vulnerabilities(self, code: str, file_path: str = None,
                                                  asset_type: str = "web") -> Dict[str, Any]:
        """
        Perform comprehensive vulnerability analysis covering all security frameworks

        Args:
            code: Source code to analyze
            file_path: Path to the source file
            asset_type: Type of asset (web, mobile, api, serverless, kernel, binary)

        Returns:
            Comprehensive analysis results with framework mappings
        """

        try:
            results = {
                'timestamp': datetime.now().isoformat(),
                'asset_type': asset_type,
                'file_path': file_path,
                'analysis_scope': 'comprehensive',
                'findings': [],
                'framework_summary': {
                    'cwe_top_25_findings': 0,
                    'sans_top_25_findings': 0,
                    'owasp_web_findings': 0,
                    'owasp_mobile_findings': 0,
                    'owasp_api_findings': 0,
                    'owasp_serverless_findings': 0,
                    'kernel_findings': 0,
                    'binary_findings': 0
                },
                'severity_distribution': {
                    'CRITICAL': 0,
                    'HIGH': 0,
                    'MEDIUM': 0,
                    'LOW': 0
                },
                'models_used': [],
                'recommendations': []
            }

            # Perform standard AI analysis
            analysis_results = await self.analyze_code_snippet(code, file_path)
            results['findings'] = analysis_results.get('findings', [])
            results['models_used'] = analysis_results.get('models_used', [])

            # Add asset-type specific analysis
            if asset_type == "kernel" or (file_path and any(ext in file_path.lower() for ext in ['.ko', '.sys', '.kext'])):
                kernel_findings = await self._analyze_with_kernel_engine(code, file_path or "kernel_code")
                results['findings'].extend(kernel_findings)
                results['models_used'].append('kernel_vulnerability_engine')

            # Calculate framework summary
            for finding in results['findings']:
                classifications = finding.get('framework_classifications', {})

                if classifications.get('cwe_top_25'):
                    results['framework_summary']['cwe_top_25_findings'] += 1
                if classifications.get('sans_top_25'):
                    results['framework_summary']['sans_top_25_findings'] += 1
                if classifications.get('owasp_web_top_10'):
                    results['framework_summary']['owasp_web_findings'] += 1
                if classifications.get('owasp_mobile_top_10'):
                    results['framework_summary']['owasp_mobile_findings'] += 1
                if classifications.get('owasp_api_top_10'):
                    results['framework_summary']['owasp_api_findings'] += 1
                if classifications.get('owasp_serverless_top_10'):
                    results['framework_summary']['owasp_serverless_findings'] += 1
                if classifications.get('kernel_vulnerability'):
                    results['framework_summary']['kernel_findings'] += 1
                if classifications.get('binary_vulnerability'):
                    results['framework_summary']['binary_findings'] += 1

                # Count severity distribution
                severity = finding.get('severity_level', finding.get('severity', 'MEDIUM')).upper()
                if severity in results['severity_distribution']:
                    results['severity_distribution'][severity] += 1

            # Generate framework-specific recommendations
            results['recommendations'] = self._generate_framework_recommendations(results)

            # Calculate comprehensive risk score
            results['comprehensive_risk_score'] = self._calculate_comprehensive_risk_score(results)

            return results

        except Exception as e:
            logger.error(f"Comprehensive vulnerability analysis failed: {e}")
            return {
                'error': str(e),
                'timestamp': datetime.now().isoformat(),
                'asset_type': asset_type,
                'file_path': file_path
            }

    def _generate_framework_recommendations(self, results: Dict[str, Any]) -> List[str]:
        """Generate recommendations based on framework findings"""

        recommendations = []
        framework_summary = results.get('framework_summary', {})

        if framework_summary.get('cwe_top_25_findings', 0) > 0:
            recommendations.append(
                "Address CWE Top 25 vulnerabilities immediately - these are the most dangerous software weaknesses"
            )

        if framework_summary.get('kernel_findings', 0) > 0:
            recommendations.append(
                "Kernel vulnerabilities detected - review for privilege escalation and memory corruption issues"
            )

        if framework_summary.get('owasp_web_findings', 0) > 0:
            recommendations.append(
                "Implement OWASP Top 10 security controls for web applications"
            )

        if framework_summary.get('owasp_api_findings', 0) > 0:
            recommendations.append(
                "Follow OWASP API Security Top 10 guidelines for API protection"
            )

        if framework_summary.get('owasp_mobile_findings', 0) > 0:
            recommendations.append(
                "Apply OWASP Mobile Top 10 security measures for mobile applications"
            )

        if framework_summary.get('owasp_serverless_findings', 0) > 0:
            recommendations.append(
                "Implement OWASP Serverless Top 10 security practices"
            )

        # Add severity-based recommendations
        severity_dist = results.get('severity_distribution', {})
        if severity_dist.get('CRITICAL', 0) > 0:
            recommendations.append(
                "CRITICAL vulnerabilities found - immediate remediation required"
            )
        elif severity_dist.get('HIGH', 0) > 0:
            recommendations.append(
                "HIGH severity vulnerabilities require prompt attention"
            )

        return recommendations

    def _calculate_comprehensive_risk_score(self, results: Dict[str, Any]) -> float:
        """Calculate comprehensive risk score based on all frameworks"""

        try:
            score = 0.0

            # Weight different framework findings
            framework_weights = {
                'cwe_top_25_findings': 20.0,
                'kernel_findings': 15.0,
                'owasp_web_findings': 10.0,
                'owasp_api_findings': 8.0,
                'owasp_mobile_findings': 8.0,
                'owasp_serverless_findings': 6.0,
                'binary_findings': 12.0
            }

            framework_summary = results.get('framework_summary', {})
            for framework, weight in framework_weights.items():
                count = framework_summary.get(framework, 0)
                score += min(count * weight, weight * 3)  # Cap contribution per framework

            # Add severity-based scoring
            severity_weights = {
                'CRITICAL': 25.0,
                'HIGH': 15.0,
                'MEDIUM': 5.0,
                'LOW': 1.0
            }

            severity_dist = results.get('severity_distribution', {})
            for severity, weight in severity_weights.items():
                count = severity_dist.get(severity, 0)
                score += count * weight

            # Normalize to 0-100 scale
            return min(score, 100.0)

        except Exception as e:
            logger.error(f"Risk score calculation failed: {e}")
            return 0.0

# Example usage
async def main():
    detector = MLVulnerabilityDetector()

    # Test code snippet
    test_code = """
    def login(username, password):
        query = f"SELECT * FROM users WHERE username='{username}' AND password='{password}'"
        return execute_query(query)
    """

    results = await detector.analyze_code_snippet(test_code)
    print(f"Vulnerability score: {results['vulnerability_score']:.2f}")
    print(f"Findings: {len(results['findings'])}")

if __name__ == "__main__":
    asyncio.run(main())